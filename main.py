import streamlit as st
import pandas as pd
import numpy as np
from scipy import stats
import statsmodels.api as sm
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.stats.stattools import durbin_watson
from statsmodels.stats.diagnostic import het_breuschpagan
import io
import matplotlib.pyplot as plt
import seaborn as sns
from docx import Document
from docx.shared import Inches

# -----------------------------------------------------------------------------
# 1. UI ìŠ¤íƒ€ì¼ë§ ë° í…Œë§ˆ ì„¤ì • (Pretendard ì ìš©)
# -----------------------------------------------------------------------------
st.set_page_config(page_title="STATERA", page_icon="ğŸ“Š", layout="wide")

plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['axes.unicode_minus'] = False
sns.set_theme(style="white")

ACRONYM_FULL = "STATistical Engine for Research & Analysis"

st.markdown(f"""
<style>
    @import url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css');
    * {{ font-family: 'Pretendard', sans-serif; }}
    
    .main-header {{ color: #0d9488; text-align: center; font-size: 3.5rem; font-weight: 800; margin-bottom: 0px; letter-spacing: -1.5px; }}
    .acronym-header {{ text-align: center; color: #64748b; font-size: 1rem; font-weight: 400; margin-bottom: 40px; text-transform: uppercase; letter-spacing: 2px; }}
    
    .guide-container {{ display: flex; gap: 20px; margin-bottom: 30px; }}
    .guide-box {{ flex: 1; background: white; border: 1px solid #e2e8f0; border-radius: 16px; padding: 24px; box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.05); }}
    .guide-label {{ font-size: 1.15rem; font-weight: 700; color: #0f172a; margin-bottom: 8px; }}
    .guide-text {{ font-size: 0.95rem; color: #64748b; line-height: 1.6; }}

    .method-info {{ background-color: #f0fdfa; border-left: 6px solid #0d9488; padding: 20px; border-radius: 8px; margin-bottom: 25px; }}
    .method-title {{ color: #0f766e; font-size: 1.3rem; font-weight: 700; margin-bottom: 10px; }}
    .method-desc {{ color: #1e293b; font-size: 1rem; line-height: 1.7; }}
    .var-badge {{ background-color: #ccfbf1; color: #0f766e; padding: 3px 10px; border-radius: 6px; font-weight: 600; font-size: 0.9rem; margin-right: 8px; }}

    .sub-method-info {{ background-color: #f8fafc; border: 1px solid #e2e8f0; padding: 15px; border-radius: 8px; margin-bottom: 20px; font-size: 0.95rem; color: #334155; }}
    
    /* ê°€ì • ê²€ì • ë°•ìŠ¤ ìŠ¤íƒ€ì¼ (í°íŠ¸ í†µì¼ìš©) */
    .assumption-box {{ background-color: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 15px; font-size: 0.95rem; color: #334155; line-height: 1.6; margin-bottom: 15px; }}
    
    .ethics-container {{ background-color: #fff7ed; border: 1px solid #ffedd5; border-radius: 12px; padding: 20px; margin-top: 50px; margin-bottom: 30px; }}
    .ethics-title {{ color: #c2410c; font-size: 1.1rem; font-weight: 700; margin-bottom: 10px; }}
    .ethics-text {{ color: #9a3412; font-size: 0.9rem; line-height: 1.6; }}

    div[data-testid="stRadio"] > div {{ flex-direction: row; gap: 25px; overflow-x: auto; }}
    .stButton>button {{ width: 100%; border-radius: 12px; background: linear-gradient(135deg, #0d9488 0%, #0f766e 100%); color: white; font-weight: 700; height: 3.8em; border: none; font-size: 1rem; }}
</style>
""", unsafe_allow_html=True)

# -----------------------------------------------------------------------------
# 2. ì‚¬ì´ë“œë°” (ì •ë³´ ë° ì—°ë½ì²˜)
# -----------------------------------------------------------------------------
with st.sidebar:
    st.markdown("<h1 style='color:#0d9488; font-size: 2rem;'>STATERA ğŸ“Š</h1>", unsafe_allow_html=True)
    st.caption(ACRONYM_FULL)
    st.markdown("---")
    
    st.markdown("### ğŸš§ Research Beta Version")
    st.info("""
    ë³¸ ì„œë¹„ìŠ¤ëŠ” ì—°êµ¬ ë°ì´í„° ë¶„ì„ì˜ ì§„ì… ì¥ë²½ì„ ë‚®ì¶”ê¸° ìœ„í•´ ê°œë°œëœ ì›¹ ê¸°ë°˜ í†µê³„ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.

    í˜„ì¬ ë¶„ì„ ì•Œê³ ë¦¬ì¦˜ì˜ íƒ€ë‹¹ë„ ê²€ì¦ ì ˆì°¨ë¥¼ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.
    """)
    
    st.markdown("---")
    st.markdown("### ğŸ“¬ Contact & Feedback")
    st.write("ì˜¤ë¥˜ ì œë³´ ë° ê¸°ëŠ¥ ì œì•ˆì€ ì–¸ì œë‚˜ í™˜ì˜í•©ë‹ˆë‹¤.")
    st.link_button("ğŸ“§ ë©”ì¼ ë³´ë‚´ê¸°", "mailto:nncj91@snu.ac.kr")
    st.caption("ì£¼ì†Œ ë³µì‚¬:")
    st.code("nncj91@snu.ac.kr", language="text")
    st.markdown("---")
    st.caption("Â© 2026 ANDA Lab. Developed by Jeongin Choe.")

# -----------------------------------------------------------------------------
# 3. ë¶„ì„ ë°©ë²•ë¡  ê°€ì´ë“œ ë°ì´í„°
# -----------------------------------------------------------------------------
METHOD_GUIDES = {
    "ê¸°ìˆ í†µê³„": {
        "title": "ğŸ“ˆ ê¸°ìˆ í†µê³„ (Descriptive Statistics)",
        "desc": "ì—°ì†í˜• ë³€ìˆ˜ì˜ í‰ê· , í‘œì¤€í¸ì°¨, ì™œë„, ì²¨ë„ ë“±ì„ ì‚°ì¶œí•˜ì—¬ ë°ì´í„°ì˜ ì „ë°˜ì ì¸ ê²½í–¥ì„ íŒŒì•…í•©ë‹ˆë‹¤.",
        "ë…ë¦½": "í•´ë‹¹ ì—†ìŒ", "ì¢…ì†": "ì—°ì†í˜• ë³€ìˆ˜",
        "use": "ì—°êµ¬ ëŒ€ìƒìì˜ ì£¼ìš” ìˆ˜ì¹˜í˜• ì§€í‘œë¥¼ ìš”ì•½í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
    },
    "ë¹ˆë„ë¶„ì„": {
        "title": "ğŸ“Š ë¹ˆë„ë¶„ì„ (Frequency Analysis)",
        "desc": "ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ë¹ˆë„, ë°±ë¶„ìœ¨, ëˆ„ì  ë¹„ìœ¨ì„ ì‚°ì¶œí•˜ì—¬ ëŒ€ìƒìì˜ ë¶„í¬ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.",
        "ë…ë¦½": "í•´ë‹¹ ì—†ìŒ", "ì¢…ì†": "ë²”ì£¼í˜• ë³€ìˆ˜",
        "use": "ì„±ë³„, í•™ë ¥ ë“± ëŒ€ìƒìì˜ ì¼ë°˜ì  íŠ¹ì„±ì„ ë³´ê³ í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
    },
    "T-ê²€ì •": {
        "title": "ğŸ‘¥ T-ê²€ì • (T-test)",
        "desc": "ì§‘ë‹¨ ê°„ í‰ê·  ì°¨ì´, 95% ì‹ ë¢°êµ¬ê°„, íš¨ê³¼í¬ê¸°(Cohen's d)ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.",
        "ë…ë¦½": "ë²”ì£¼í˜• (2ì§‘ë‹¨)", "ì¢…ì†": "ì—°ì†í˜• ë³€ìˆ˜",
        "use": "ë‘ ê·¸ë£¹ ê°„ì˜ ê²°ê³¼ê°’ ì°¨ì´ë¥¼ ë¹„êµí•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
    },
    "ë¶„ì‚°ë¶„ì„": {
        "title": "ğŸ« ë¶„ì‚°ë¶„ì„ (ANOVA)",
        "desc": "ì„¸ ê°œ ì´ìƒì˜ ê·¸ë£¹ ê°„ í‰ê·  ì°¨ì´ì™€ íš¨ê³¼í¬ê¸°(Eta-squared)ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.",
        "ë…ë¦½": "ë²”ì£¼í˜• (3ì§‘ë‹¨ ì´ìƒ)", "ì¢…ì†": "ì—°ì†í˜• ë³€ìˆ˜",
        "use": "í•™ë ¥ì´ë‚˜ ì—°ë ¹ëŒ€ë³„ ì ìˆ˜ ì°¨ì´ ë¶„ì„ ì‹œ ì‚¬ìš©í•©ë‹ˆë‹¤."
    },
    "ìƒê´€ë¶„ì„": {
        "title": "ğŸ”— ìƒê´€ë¶„ì„ (Correlation Analysis)",
        "desc": "ë‹¤ìˆ˜ ë³€ìˆ˜ ê°„ì˜ ê¸°ìˆ í†µê³„(í‰ê· , SD)ì™€ Pearson ìƒê´€ê³„ìˆ˜ í–‰ë ¬ì„ í†µí•© ë¶„ì„í•©ë‹ˆë‹¤.",
        "ë…ë¦½": "ì—°ì†í˜•", "ì¢…ì†": "ì—°ì†í˜•",
        "use": "ë³€ìˆ˜ë“¤ ê°„ì˜ ê´€ê³„ì„±ì„ ì¢…í•©ì ìœ¼ë¡œ ë³´ê³ í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
    },
    "íšŒê·€ë¶„ì„": {
        "title": "ğŸ¯ íšŒê·€ë¶„ì„ (Regression Analysis)",
        "desc": "ë…ë¦½ë³€ìˆ˜ì˜ ì˜í–¥ë ¥, ëª¨í˜• ì í•©ë„(RÂ²), ê³„ìˆ˜ì˜ ì‹ ë¢°êµ¬ê°„ì„ ì‚°ì¶œí•©ë‹ˆë‹¤.",
        "ë…ë¦½": "ì—°ì†í˜• ë˜ëŠ” ë²”ì£¼í˜•", "ì¢…ì†": "ì—°ì†í˜•(ì„ í˜•) ë˜ëŠ” ì´ë¶„ ë²”ì£¼í˜•(ë¡œì§€ìŠ¤í‹±)",
        "use": "íŠ¹ì • ìš”ì¸ì´ ê²°ê³¼ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì˜ í¬ê¸°ë¥¼ ìˆ˜ì¹˜í™”í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
    }
}

TTEST_SUB_GUIDES = {
    "ë…ë¦½í‘œë³¸": "ì„œë¡œ ë‹¤ë¥¸ ë‘ ì§‘ë‹¨ì˜ í‰ê· ì„ ë¹„êµí•©ë‹ˆë‹¤. (ì˜ˆ: ë‚¨ì„± vs ì—¬ì„±)",
    "ëŒ€ì‘í‘œë³¸": "ë™ì¼ ì§‘ë‹¨ì˜ ì „/í›„ í‰ê·  ë³€í™”ë¥¼ ë¹„êµí•©ë‹ˆë‹¤. (ì˜ˆ: êµìœ¡ ì „ vs êµìœ¡ í›„)",
    "ë‹¨ì¼í‘œë³¸": "ì§‘ë‹¨ì˜ í‰ê· ì„ íŠ¹ì • ê¸°ì¤€ê°’ê³¼ ë¹„êµí•©ë‹ˆë‹¤. (ì˜ˆ: ìš°ë¦¬ ë°˜ í‰ê·  vs ê¸°ì¤€ ì ìˆ˜)"
}

# -----------------------------------------------------------------------------
# 4. ìœ í‹¸ë¦¬í‹° ë° [ê°€ì • ê²€ì • & í•´ì„ ì—”ì§„]
# -----------------------------------------------------------------------------
def get_stars(p):
    if p < .001: return "***"
    elif p < .01: return "**"
    elif p < .05: return "*"
    else: return ""

def format_p(p): return "<.001" if p < .001 else f"{p:.3f}"

# --- ê°€ì • ê²€ì • í•¨ìˆ˜ë“¤ (ê°•ì¡° ì œê±°ë¨) ---
def check_normality_shapiro(data, name):
    """ì •ê·œì„± ê²€ì • (N < 30: Shapiro-Wilk, N >= 30: CLT)"""
    data = data.dropna()
    n = len(data)
    if n < 3: return "N < 3 (ê²€ì • ë¶ˆê°€)", False
    
    if n >= 30:
        return f"í‘œë³¸ ìˆ˜ {n}ê°œë¡œ ëŒ€í‘œë³¸(Nâ‰¥30)ì— í•´ë‹¹í•˜ì—¬ ì¤‘ì‹¬ê·¹í•œì •ë¦¬(CLT)ì— ì˜í•´ ì •ê·œì„± ê°€ì •ì„ ì¶©ì¡±í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.", True
    else:
        stat, p = stats.shapiro(data)
        if p >= 0.05:
            return f"Shapiro-Wilk ê²€ì • ê²°ê³¼(p={format_p(p)}), ì •ê·œì„± ê°€ì •ì„ ë§Œì¡±í•©ë‹ˆë‹¤.", True
        else:
            return f"Shapiro-Wilk ê²€ì • ê²°ê³¼(p={format_p(p)}), ì •ê·œì„± ê°€ì •ì„ ìœ„ë°°í•  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.", False

def check_homogeneity_levene(group_data_list):
    """ë“±ë¶„ì‚°ì„± ê²€ì • (Levene)"""
    stat, p = stats.levene(*group_data_list)
    if p >= 0.05:
        return f"Levene ê²€ì • ê²°ê³¼(p={format_p(p)}), ë“±ë¶„ì‚° ê°€ì •ì„ ë§Œì¡±í•©ë‹ˆë‹¤.", True
    else:
        return f"Levene ê²€ì • ê²°ê³¼(p={format_p(p)}), ë“±ë¶„ì‚° ê°€ì •ì„ ìœ„ë°°í•˜ì˜€ìŠµë‹ˆë‹¤ (ì´ë¶„ì‚°).", False

def check_independence_dw(resid):
    """ë…ë¦½ì„± ê²€ì • (Durbin-Watson)"""
    dw = durbin_watson(resid)
    if 1.5 <= dw <= 2.5:
        return f"Durbin-Watson í†µê³„ëŸ‰({dw:.2f})ì´ 2ì— ê°€ê¹Œì›Œ ì”ì°¨ì˜ ë…ë¦½ì„± ê°€ì •ì„ ë§Œì¡±í•©ë‹ˆë‹¤.", True
    else:
        return f"Durbin-Watson í†µê³„ëŸ‰({dw:.2f})ì´ ê¸°ì¤€(1.5~2.5)ì„ ë²—ì–´ë‚˜ ìê¸°ìƒê´€ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.", False

def calc_vif(X):
    """ë‹¤ì¤‘ê³µì„ ì„± (VIF) ê³„ì‚°"""
    vif_data = pd.DataFrame()
    vif_data["feature"] = X.columns
    vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]
    return vif_data

def calc_cohens_d(x1, x2):
    """T-testìš© íš¨ê³¼í¬ê¸°(Cohen's d) ê³„ì‚°"""
    nx1, nx2 = len(x1), len(x2)
    s1, s2 = np.std(x1, ddof=1), np.std(x2, ddof=1)
    s_pooled = np.sqrt(((nx1 - 1) * s1**2 + (nx2 - 1) * s2**2) / (nx1 + nx2 - 2))
    return (np.mean(x1) - np.mean(x2)) / s_pooled

def calc_corr_ci(r, n, alpha=0.05):
    """ìƒê´€ê³„ìˆ˜ì˜ 95% ì‹ ë¢°êµ¬ê°„ ê³„ì‚°"""
    if n <= 3: return np.nan, np.nan
    z = np.arctanh(r)
    se = 1 / np.sqrt(n - 3)
    z_crit = stats.norm.ppf(1 - alpha/2)
    lo_z, hi_z = z - z_crit * se, z + z_crit * se
    return np.tanh(lo_z), np.tanh(hi_z)

# --- í•´ì„ ì—”ì§„ (ê°•ì¡° ì œê±°ë¨) ---
def interpret_effect_size(val, method):
    abs_val = abs(val)
    if method == "cohen_d":
        if abs_val < 0.2: return "ì‘ì€(Small)"
        elif abs_val < 0.5: return "ì¤‘ê°„(Medium)"
        else: return "í°(Large)"
    elif method == "eta_sq": 
        if abs_val < 0.01: return "ë¯¸ë¯¸í•œ"
        elif abs_val < 0.06: return "ì‘ì€(Small)"
        elif abs_val < 0.14: return "ì¤‘ê°„(Medium)"
        else: return "í°(Large)"
    elif method == "pearson_r":
        if abs_val < 0.3: return "ì•½í•œ"
        elif abs_val < 0.7: return "ëšœë ·í•œ"
        else: return "ê°•í•œ"
    return ""

def get_auto_interpretation(method, p_val, stats_dict=None):
    if stats_dict is None: stats_dict = {}
    is_sig = p_val < 0.05
    sig_text = "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´(ë˜ëŠ” ê´€ê³„)ê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤(p < .05)." if is_sig else "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´(ë˜ëŠ” ê´€ê³„)ê°€ í™•ì¸ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤(p >= .05)."
    
    explanation = ""
    # [ìˆ˜ì •] ê¸°ìˆ í†µê³„, ë¹ˆë„ë¶„ì„, ìƒê´€ë¶„ì„(í‘œ í˜•íƒœ)ì€ p-value í†µí•© í•´ì„ ì œì™¸
    if method not in ["ê¸°ìˆ í†µê³„", "ë¹ˆë„ë¶„ì„", "ìƒê´€ë¶„ì„"]:
        explanation = f"ğŸ“Œ [1. ê²°ë¡  ìš”ì•½] {sig_text}\n\n"
    
    # ê°€ì • ê²€ì • ê²°ê³¼ ìš”ì•½
    assump_fails = stats_dict.get('assump_fails', [])
    if assump_fails:
        explanation += f"âš ï¸ [ì£¼ì˜] ë¶„ì„ ê°€ì • ì¤‘ {', '.join(assump_fails)} ì¡°ê±´ì´ ì¶©ì¡±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê²°ê³¼ í•´ì„ì— ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n\n"

    # ìƒì„¸ í•´ì„
    if method == "ê¸°ìˆ í†µê³„":
        non_normal_vars = stats_dict.get('non_normal_vars', [])
        explanation = "ğŸ“Œ [ë°ì´í„° ë¶„í¬ í•´ì„]\n"
        if not non_normal_vars:
            explanation += "ë¶„ì„ëœ ë³€ìˆ˜ë“¤ì€ ì™œë„(Abs < 2)ì™€ ì²¨ë„(Abs < 7) ê¸°ì¤€ ë‚´ì— ìˆì–´, ì •ê·œë¶„í¬ì™€ ìœ ì‚¬í•œ í˜•íƒœë¥¼ ë³´ì…ë‹ˆë‹¤."
        else:
            explanation += f"[{', '.join(non_normal_vars)}] ë³€ìˆ˜ëŠ” ì •ê·œë¶„í¬ í˜•íƒœì—ì„œ ë²—ì–´ë‚˜ ìˆìŠµë‹ˆë‹¤ (Ref: West et al., 1995)."

    elif method == "ë¹ˆë„ë¶„ì„":
        explanation = "ğŸ“Œ [í•´ì„ ê°€ì´ë“œ]\n'ë¹„ìœ¨(%)'ì€ ì „ì²´ ëŒ€ë¹„ í•´ë‹¹ ë²”ì£¼ì˜ í¬ê¸°ë¥¼, 'ëˆ„ì  ë¹„ìœ¨'ì€ ìˆœì°¨ì ìœ¼ë¡œ í•©ì‚°ëœ ë¹„ì¤‘ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ë°ì´í„°ê°€ íŠ¹ì • ë²”ì£¼ì— í¸ì¤‘ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤."

    elif method == "T-ê²€ì •":
        d_val = stats_dict.get('d', 0)
        ci_lo, ci_hi = stats_dict.get('ci_lo', 0), stats_dict.get('ci_hi', 0)
        d_desc = interpret_effect_size(d_val, "cohen_d")
        explanation += f"ğŸ“Œ [2. íš¨ê³¼í¬ê¸° ë° ì‹ ë¢°êµ¬ê°„]\n"
        explanation += f"- Cohen's d = {d_val:.2f}: ë‘ ì§‘ë‹¨ ê°„ì—ëŠ” '{d_desc}' ìˆ˜ì¤€ì˜ ì‹¤ì§ˆì  ì°¨ì´ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\n"
        explanation += f"- 95% ì‹ ë¢°êµ¬ê°„ [{ci_lo:.2f}, {ci_hi:.2f}]: ë°˜ë³µ ì—°êµ¬ ì‹œ, ì‹¤ì œ í‰ê·  ì°¨ì´ëŠ” ì´ ë²”ìœ„ ë‚´ì— ì¡´ì¬í•  í™•ë¥ ì´ 95%ì…ë‹ˆë‹¤."

    elif method == "ë¶„ì‚°ë¶„ì„":
        eta = stats_dict.get('eta', 0)
        eta_desc = interpret_effect_size(eta, "eta_sq")
        explanation += f"ğŸ“Œ [2. íš¨ê³¼í¬ê¸° í•´ì„]\n"
        explanation += f"- Eta-squared ($\eta^2$) = {eta:.3f}: ë…ë¦½ ë³€ìˆ˜(ì§‘ë‹¨ êµ¬ë¶„)ê°€ ì¢…ì† ë³€ìˆ˜ì˜ ë³€ë™ì„ ì•½ {eta*100:.1f}% ì„¤ëª…í•˜ê³  ìˆìœ¼ë©°, ì´ëŠ” '{eta_desc}' ìˆ˜ì¤€ì˜ ì„¤ëª…ë ¥ì…ë‹ˆë‹¤."

    elif method == "ìƒê´€ë¶„ì„":
        explanation = "ğŸ“Œ [í‘œ í•´ì„ ê°€ì´ë“œ]\n"
        explanation += "- M: í‰ê· , SD: í‘œì¤€í¸ì°¨\n"
        explanation += "- ëŒ€ê°ì„  ì•„ë˜ì˜ ìˆ˜ì¹˜ëŠ” ë‘ ë³€ìˆ˜ ê°„ì˜ Pearson ìƒê´€ê³„ìˆ˜(r)ì…ë‹ˆë‹¤.\n"
        explanation += "- ë³„í‘œ(*): * p<.05, ** p<.01, *** p<.001 ìˆ˜ì¤€ì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤."

    elif method == "íšŒê·€ë¶„ì„":
        r2 = stats_dict.get('r2', 0)
        explanation += f"ğŸ“Œ [2. ëª¨í˜• ì í•©ë„ í•´ì„]\n"
        explanation += f"- ê²°ì •ê³„ìˆ˜($R^2$) = {r2:.3f}: êµ¬ì¶•ëœ íšŒê·€ ëª¨í˜•ì€ ì¢…ì† ë³€ìˆ˜ ì „ì²´ ë³€ë™ì˜ ì•½ {r2*100:.1f}%ë¥¼ ì„¤ëª…í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
        explanation += "- ê° ë…ë¦½ ë³€ìˆ˜ì˜ B(ë¹„í‘œì¤€í™” ê³„ìˆ˜) ì‹ ë¢°êµ¬ê°„ì´ 0ì„ í¬í•¨í•˜ì§€ ì•Šì„ ë•Œ, í•´ë‹¹ ë³€ìˆ˜ëŠ” ìœ ì˜í•œ ì˜í–¥ë ¥ì´ ìˆë‹¤ê³  íŒë‹¨í•©ë‹ˆë‹¤."

    return explanation

def create_word_report(df, interpretation, plot_buf=None, assumption_text=""):
    doc = Document(); doc.add_heading('STATERA Analysis Report', 0)
    
    if assumption_text:
        doc.add_heading('Assumption Checks', level=1)
        doc.add_paragraph(assumption_text.replace("<br>", "\n"))

    doc.add_heading('Statistical Results', level=1)
    table = doc.add_table(rows=1, cols=len(df.columns)); table.style = 'Table Grid'
    for i, col in enumerate(df.columns): table.rows[0].cells[i].text = str(col)
    for _, row in df.iterrows():
        cells = table.add_row().cells
        for i, val in enumerate(row): cells[i].text = str(val)
        
    if plot_buf: doc.add_heading('Visualization', level=1); doc.add_picture(plot_buf, width=Inches(5.5))
    doc.add_heading('AI Interpretation', level=1); doc.add_paragraph(interpretation)
    bio = io.BytesIO(); doc.save(bio); bio.seek(0); return bio

def get_plot_buffer():
    buf = io.BytesIO(); plt.savefig(buf, format='png', bbox_inches='tight', dpi=300); buf.seek(0); plt.close(); return buf

# -----------------------------------------------------------------------------
# 5. ë©”ì¸ ì›Œí¬í”Œë¡œìš°
# -----------------------------------------------------------------------------
st.markdown('<h1 class="main-header">STATERA</h1>', unsafe_allow_html=True)
st.markdown(f'<p class="acronym-header">{ACRONYM_FULL}</p>', unsafe_allow_html=True)

st.markdown(f"""
<div class="guide-container">
    <div class="guide-box"><div class="guide-label">ğŸ”’ ë°ì´í„° ë³´ì•ˆ ì•ˆë‚´</div><div class="guide-text">ë¶„ì„ ì¦‰ì‹œ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì—ì„œ ì‚­ì œí•˜ë©°, ì„œë²„ì— ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</div></div>
    <div class="guide-box"><div class="guide-label">ğŸ“„ ë°ì´í„° í˜•ì‹ ê°€ì´ë“œ</div><div class="guide-text">íŒŒì¼ì˜ ì²« ë²ˆì§¸ í–‰ì—ëŠ” ë°˜ë“œì‹œ ë³€ìˆ˜ëª…ì´ í¬í•¨ë˜ì–´ì•¼ ì‹œìŠ¤í…œì´ ì¸ì‹í•©ë‹ˆë‹¤.</div></div>
</div>
""", unsafe_allow_html=True)

up_file = st.file_uploader("Upload Data", type=["xlsx", "csv"], label_visibility="collapsed")

if up_file:
    df = pd.read_excel(up_file) if up_file.name.endswith('xlsx') else pd.read_csv(up_file)
    st.success(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ {len(df)}ê±´ì˜ ì‚¬ë¡€ê°€ ì¸ì‹ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    st.markdown('<div class="section-title"><span class="step-badge">01</span> ë¶„ì„ ë°©ë²• ì„ íƒ</div>', unsafe_allow_html=True)
    method = st.radio("ìˆ˜í–‰í•  í†µê³„ ê¸°ë²•ì„ í´ë¦­í•˜ì„¸ìš”", list(METHOD_GUIDES.keys()), horizontal=True, label_visibility="collapsed")

    guide = METHOD_GUIDES[method]
    st.markdown(f"""
    <div class="method-info">
        <div class="method-title">{guide['title']}</div>
        <div class="method-desc">
            {guide['desc']}<br>
            <span class="var-badge">ë…ë¦½ ë³€ìˆ˜</span> {guide['ë…ë¦½']} &nbsp; <span class="var-badge">ì¢…ì† ë³€ìˆ˜</span> {guide['ì¢…ì†']}<br>
            <b>í™œìš© ì˜ˆì‹œ:</b> {guide['use']}
        </div>
    </div>
    """, unsafe_allow_html=True)

    num_cols = df.select_dtypes(include=[np.number]).columns
    all_cols = df.columns
    final_df, interpretation, plot_img = None, "", None
    assumption_report = "" 
    assump_fails = [] 

    # -------------------------------------------------------------------------
    # 1) ê¸°ìˆ í†µê³„
    # -------------------------------------------------------------------------
    if method == "ê¸°ìˆ í†µê³„":
        sel_v = st.multiselect("ë¶„ì„í•  ì—°ì†í˜• ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”", num_cols)
        if st.button("ë¶„ì„ ì‹¤í–‰") and sel_v:
            desc = df[sel_v].describe().T
            desc['skew'] = df[sel_v].skew()
            desc['kurt'] = df[sel_v].kurt()
            
            final_df = desc[['count', 'mean', 'std', 'min', '50%', 'max', 'skew', 'kurt']].reset_index()
            final_df.columns = ['ë³€ìˆ˜ëª…', 'N', 'í‰ê· (M)', 'í‘œì¤€í¸ì°¨(SD)', 'ìµœì†Ÿê°’', 'ì¤‘ìœ„ìˆ˜(Median)', 'ìµœëŒ“ê°’', 'ì™œë„', 'ì²¨ë„']
            
            non_normal_vars = []
            for idx, row in final_df.iterrows():
                if abs(row['ì™œë„']) >= 2 or abs(row['ì²¨ë„']) >= 7:
                    non_normal_vars.append(row['ë³€ìˆ˜ëª…'])
            
            interpretation = get_auto_interpretation("ê¸°ìˆ í†µê³„", 1.0, {'non_normal_vars': non_normal_vars})
            plt.figure(figsize=(10, 5)); sns.boxplot(data=df[sel_v], palette="Set2"); plot_img = get_plot_buffer()

    # -------------------------------------------------------------------------
    # 2) ë¹ˆë„ë¶„ì„
    # -------------------------------------------------------------------------
    elif method == "ë¹ˆë„ë¶„ì„":
        sel_v = st.multiselect("ë¶„ì„í•  ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”", all_cols)
        if st.button("ë¶„ì„ ì‹¤í–‰") and sel_v:
            res_list = []
            for col in sel_v:
                c = df[col].value_counts().reset_index()
                c.columns = ['ë²”ì£¼', 'ë¹ˆë„(N)']
                total = c['ë¹ˆë„(N)'].sum()
                c['ë¹„ìœ¨(%)'] = (c['ë¹ˆë„(N)'] / total * 100).round(1)
                c['ëˆ„ì  ë¹„ìœ¨(%)'] = c['ë¹„ìœ¨(%)'].cumsum()
                c.insert(0, 'ë³€ìˆ˜ëª…', col)
                res_list.append(c)
            final_df = pd.concat(res_list)
            interpretation = get_auto_interpretation("ë¹ˆë„ë¶„ì„", 1.0)
            plt.figure(figsize=(10, 5)); sns.countplot(x=sel_v[0], data=df, palette="pastel"); plot_img = get_plot_buffer()

    # -------------------------------------------------------------------------
    # 3) T-ê²€ì •
    # -------------------------------------------------------------------------
    elif method == "T-ê²€ì •":
        t_mode = st.radio("ì„¸ë¶€ ìœ í˜• ì„ íƒ", list(TTEST_SUB_GUIDES.keys()), horizontal=True)
        st.markdown(f'<div class="sub-method-info">ğŸ’¡ {TTEST_SUB_GUIDES[t_mode]}</div>', unsafe_allow_html=True)
        
        if t_mode == "ë…ë¦½í‘œë³¸":
            g, y = st.selectbox("ì§‘ë‹¨ ë³€ìˆ˜ (ë²”ì£¼í˜•)", all_cols), st.selectbox("ê²°ê³¼ ë³€ìˆ˜ (ì—°ì†í˜•)", num_cols)
            if st.button("ë¶„ì„ ì‹¤í–‰"):
                gps = df[g].unique()
                if len(gps) != 2:
                    st.error("ë…ë¦½í‘œë³¸ T-ê²€ì •ì€ ì§‘ë‹¨ì´ ì •í™•íˆ 2ê°œì—¬ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    g1 = df[df[g]==gps[0]][y].dropna()
                    g2 = df[df[g]==gps[1]][y].dropna()
                    
                    msg_n1, pass_n1 = check_normality_shapiro(g1, gps[0])
                    msg_n2, pass_n2 = check_normality_shapiro(g2, gps[1])
                    if not (pass_n1 and pass_n2): assump_fails.append("ì •ê·œì„±")

                    msg_var, equal_var = check_homogeneity_levene([g1, g2])
                    if not equal_var: assump_fails.append("ë“±ë¶„ì‚°ì„±")
                    
                    assumption_report = f"- ì •ê·œì„±: {msg_n1}<br>- ì •ê·œì„±: {msg_n2}<br>- ë“±ë¶„ì‚°ì„±: {msg_var}"
                    
                    t_stat, p = stats.ttest_ind(g1, g2, equal_var=equal_var)
                    
                    mean_diff = np.mean(g1) - np.mean(g2)
                    n1, n2 = len(g1), len(g2)
                    se_diff = np.sqrt(np.var(g1, ddof=1)/n1 + np.var(g2, ddof=1)/n2)
                    
                    df_t = n1 + n2 - 2
                    ci_crit = stats.t.ppf(0.975, df_t)
                    ci_lower = mean_diff - ci_crit * se_diff
                    ci_upper = mean_diff + ci_crit * se_diff
                    d_val = calc_cohens_d(g1, g2)

                    final_df = pd.DataFrame({
                        "ë³€ìˆ˜ëª…": [y],
                        "ì§‘ë‹¨ë¹„êµ": [f"{gps[0]} vs {gps[1]}"],
                        "í‰ê·  ì°¨ì´": [f"{mean_diff:.2f}"],
                        "í‘œì¤€ì˜¤ì°¨(SE)": [f"{se_diff:.2f}"],
                        "95% CI (Lower)": [f"{ci_lower:.2f}"],
                        "95% CI (Upper)": [f"{ci_upper:.2f}"],
                        "tê°’": [f"{t_stat:.2f}"],
                        "df": [f"{df_t}"],
                        "pê°’": [f"{format_p(p)}{get_stars(p)}"],
                        "Cohen's d": [f"{d_val:.2f}"]
                    })
                    
                    interpretation = get_auto_interpretation("T-ê²€ì •", p, {'d': d_val, 'ci_lo': ci_lower, 'ci_hi': ci_upper, 'assump_fails': assump_fails})
                    if not equal_var: interpretation += "\n(ì°¸ê³ : ë“±ë¶„ì‚° ìœ„ë°°ë¡œ Welch's T-test ì ìš©ë¨)"
                    plt.figure(figsize=(6, 5)); sns.barplot(x=g, y=y, data=df, palette="mako"); plot_img = get_plot_buffer()
        
        elif t_mode == "ëŒ€ì‘í‘œë³¸":
            v1, v2 = st.selectbox("ì‚¬ì „ ë³€ìˆ˜", num_cols), st.selectbox("ì‚¬í›„ ë³€ìˆ˜", num_cols)
            if st.button("ë¶„ì„ ì‹¤í–‰"):
                pair_data = df[[v1, v2]].dropna()
                diff = pair_data[v1] - pair_data[v2]
                
                msg_n, pass_n = check_normality_shapiro(diff, "Difference")
                if not pass_n: assump_fails.append("ì •ê·œì„±(ì°¨ì´ê°’)")
                assumption_report = f"- ì •ê·œì„±(ì°¨ì´ê°’): {msg_n}"

                t_stat, p = stats.ttest_rel(pair_data[v1], pair_data[v2])
                
                mean_diff = np.mean(diff)
                se_diff = stats.sem(diff)
                df_t = len(diff) - 1
                ci = stats.t.interval(0.95, df_t, loc=mean_diff, scale=se_diff)
                d_val = mean_diff / np.std(diff, ddof=1) 

                final_df = pd.DataFrame({
                    "ë¹„êµ": [f"{v1} - {v2}"],
                    "í‰ê·  ì°¨ì´": [f"{mean_diff:.2f}"],
                    "í‘œì¤€ì˜¤ì°¨(SE)": [f"{se_diff:.2f}"],
                    "95% CI (Lower)": [f"{ci[0]:.2f}"],
                    "95% CI (Upper)": [f"{ci[1]:.2f}"],
                    "tê°’": [f"{t_stat:.2f}"],
                    "pê°’": [f"{format_p(p)}{get_stars(p)}"],
                    "Cohen's d": [f"{d_val:.2f}"]
                })
                
                interpretation = get_auto_interpretation("T-ê²€ì •", p, {'d': d_val, 'ci_lo': ci[0], 'ci_hi': ci[1], 'assump_fails': assump_fails})
                plt.figure(figsize=(6, 5)); sns.pointplot(data=pair_data, palette="flare"); plot_img = get_plot_buffer()

        elif t_mode == "ë‹¨ì¼í‘œë³¸":
            v, mu = st.selectbox("ë¶„ì„ ë³€ìˆ˜", num_cols), st.number_input("ê²€ì • ê¸°ì¤€ê°’", value=0.0)
            if st.button("ë¶„ì„ ì‹¤í–‰"):
                clean_data = df[v].dropna()
                msg_n, pass_n = check_normality_shapiro(clean_data, v)
                if not pass_n: assump_fails.append("ì •ê·œì„±")
                assumption_report = f"- ì •ê·œì„±: {msg_n}"
                
                t_stat, p = stats.ttest_1samp(clean_data, mu)
                
                mean_val = np.mean(clean_data)
                mean_diff = mean_val - mu
                se = stats.sem(clean_data)
                ci = stats.t.interval(0.95, len(clean_data)-1, loc=mean_val, scale=se)

                final_df = pd.DataFrame({
                    "ë³€ìˆ˜": [v],
                    "í‘œë³¸ í‰ê· ": [f"{mean_val:.2f}"],
                    "ì°¨ì´(Mean-Î¼)": [f"{mean_diff:.2f}"],
                    "95% CI (Lower)": [f"{ci[0]:.2f}"],
                    "95% CI (Upper)": [f"{ci[1]:.2f}"],
                    "tê°’": [f"{t_stat:.2f}"],
                    "pê°’": [f"{format_p(p)}{get_stars(p)}"]
                })
                interpretation = get_auto_interpretation("T-ê²€ì •", p, {'assump_fails': assump_fails})
                plt.figure(figsize=(6, 5)); sns.histplot(clean_data, kde=True); plt.axvline(mu, color='red', ls='--'); plot_img = get_plot_buffer()

    # -------------------------------------------------------------------------
    # 4) ë¶„ì‚°ë¶„ì„
    # -------------------------------------------------------------------------
    elif method == "ë¶„ì‚°ë¶„ì„":
        g, y = st.selectbox("ì§‘ë‹¨ ë³€ìˆ˜ (3ì§‘ë‹¨ ì´ìƒ)", all_cols), st.selectbox("ê²°ê³¼ ë³€ìˆ˜ (ì—°ì†í˜•)", num_cols)
        if st.button("ë¶„ì„ ì‹¤í–‰"):
            temp_df = df[[g, y]].dropna().rename(columns={g:'Group_Var', y:'Target_Var'})
            groups = [temp_df[temp_df['Group_Var']==val]['Target_Var'] for val in temp_df['Group_Var'].unique()]

            msg_var, equal_var = check_homogeneity_levene(groups)
            if not equal_var: assump_fails.append("ë“±ë¶„ì‚°ì„±")
            assumption_report = f"- ë“±ë¶„ì‚°ì„±: {msg_var}<br>(ì°¸ê³ : ì •ê·œì„±ì€ ê° ì§‘ë‹¨ë³„ N>=30ì¼ ê²½ìš° CLTì— ì˜í•´ ì¶©ì¡± ê°„ì£¼)"
            
            model = ols('Target_Var ~ C(Group_Var)', data=temp_df).fit()
            anova_table = anova_lm(model, typ=2)
            
            ss_between = anova_table.loc['C(Group_Var)', 'sum_sq']
            ss_resid = anova_table.loc['Residual', 'sum_sq']
            eta_sq = ss_between / (ss_between + ss_resid)
            
            f_val = anova_table.loc['C(Group_Var)', 'F']
            p_val = anova_table.loc['C(Group_Var)', 'PR(>F)']
            df_bet = int(anova_table.loc['C(Group_Var)', 'df'])
            df_resid = int(anova_table.loc['Residual', 'df'])

            final_df = pd.DataFrame({
                "ìš”ì¸": ["ì§‘ë‹¨ ê°„", "ì§‘ë‹¨ ë‚´(ì˜¤ì°¨)"],
                "ì œê³±í•©(SS)": [f"{ss_between:.2f}", f"{ss_resid:.2f}"],
                "ììœ ë„(df)": [df_bet, df_resid],
                "í‰ê· ì œê³±(MS)": [f"{ss_between/df_bet:.2f}", f"{ss_resid/df_resid:.2f}"],
                "Fê°’": [f"{f_val:.2f}", ""],
                "pê°’": [f"{format_p(p_val)}{get_stars(p_val)}", ""],
                "Eta-squared": [f"{eta_sq:.3f}", ""]
            })
            
            interpretation = get_auto_interpretation("ë¶„ì‚°ë¶„ì„", p_val, {'eta': eta_sq, 'assump_fails': assump_fails})
            if not equal_var: interpretation += "\n(ê¶Œê³ : ë“±ë¶„ì‚° ìœ„ë°° ì‹œ Welch's ANOVAë¥¼ ê³ ë ¤í•˜ì‹­ì‹œì˜¤.)"
            plt.figure(figsize=(8, 5)); sns.boxplot(x=g, y=y, data=df, palette="viridis"); plot_img = get_plot_buffer()

    # -------------------------------------------------------------------------
    # 5) ìƒê´€ë¶„ì„ (ì—…ê·¸ë ˆì´ë“œ: APA ìŠ¤íƒ€ì¼ í‘œ ìƒì„±)
    # -------------------------------------------------------------------------
    elif method == "ìƒê´€ë¶„ì„":
        sel_vars = st.multiselect("ë¶„ì„í•  ë³€ìˆ˜ë“¤ì„ ëª¨ë‘ ì„ íƒí•˜ì„¸ìš” (2ê°œ ì´ìƒ)", num_cols)
        
        if st.button("ë¶„ì„ ì‹¤í–‰") and len(sel_vars) >= 2:
            target_df = df[sel_vars].dropna()
            n = len(target_df)
            
            desc_stats = target_df.describe().T[['mean', 'std']]
            cols = ['M', 'SD'] + [str(i+1) for i in range(len(sel_vars))]
            corr_table = pd.DataFrame(index=sel_vars, columns=cols)
            
            check_normality_msgs = []
            
            for i, var_row in enumerate(sel_vars):
                corr_table.loc[var_row, 'M'] = f"{desc_stats.loc[var_row, 'mean']:.2f}"
                corr_table.loc[var_row, 'SD'] = f"{desc_stats.loc[var_row, 'std']:.2f}"
                
                msg_n, pass_n = check_normality_shapiro(target_df[var_row], var_row)
                if not pass_n: assump_fails.append(f"ì •ê·œì„±({var_row})")
                check_normality_msgs.append(f"- {var_row}: {msg_n}")

                for j, var_col in enumerate(sel_vars):
                    if i == j:
                        corr_table.iloc[i, j+2] = "1"
                    elif i > j:
                        r, p = stats.pearsonr(target_df[var_row], target_df[var_col])
                        star = get_stars(p)
                        corr_table.iloc[i, j+2] = f"{r:.2f}{star}"
                    else:
                        corr_table.iloc[i, j+2] = ""
            
            new_index = [f"{i+1}. {v}" for i, v in enumerate(sel_vars)]
            corr_table.index = new_index
            
            final_df = corr_table
            assumption_report = "<br>".join(check_normality_msgs)
            
            interpretation = get_auto_interpretation("ìƒê´€ë¶„ì„", 1.0, {'assump_fails': assump_fails})
            
            max_r = 0
            max_pair = ""
            for i in range(len(sel_vars)):
                for j in range(i):
                    val_str = str(corr_table.iloc[i, j+2]).replace('*', '')
                    try:
                        val = float(val_str)
                        if abs(val) > abs(max_r):
                            max_r = val
                            max_pair = f"'{sel_vars[i]}' - '{sel_vars[j]}'"
                    except: pass
            
            if max_pair:
                interpretation += f"\nğŸ’¡ [í•µì‹¬ ë°œê²¬] ë¶„ì„ëœ ë³€ìˆ˜ ì¤‘ {max_pair} ê°„ì˜ ê´€ê³„ê°€ ê°€ì¥ ê°•í•˜ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤ (r={max_r:.2f})."

            plt.figure(figsize=(8, 6)); sns.heatmap(target_df.corr(), annot=True, cmap="coolwarm", vmin=-1, vmax=1); plot_img = get_plot_buffer()

    # -------------------------------------------------------------------------
    # 6) íšŒê·€ë¶„ì„
    # -------------------------------------------------------------------------
    elif method == "íšŒê·€ë¶„ì„":
        reg_t = st.radio("ìœ í˜•", ["ì„ í˜• íšŒê·€", "ë¡œì§€ìŠ¤í‹± íšŒê·€"], horizontal=True)
        x_vars = st.multiselect("ë…ë¦½ ë³€ìˆ˜ ì„ íƒ", [c for c in num_cols])
        y_var = st.selectbox("ì¢…ì† ë³€ìˆ˜ ì„ íƒ", num_cols)
        
        if st.button("ë¶„ì„ ì‹¤í–‰") and x_vars:
            X = sm.add_constant(df[x_vars].dropna())
            Y = df[y_var].loc[X.index] 

            if "ì„ í˜•" in reg_t:
                model = sm.OLS(Y, X).fit()
                
                # ê°€ì • ê²€ì •
                vif_df = calc_vif(X)
                high_vif = vif_df[vif_df['VIF'] > 10]['feature'].tolist()
                if "const" in high_vif: high_vif.remove("const")
                
                msg_dw, pass_dw = check_independence_dw(model.resid)
                _, p_het, _, _ = het_breuschpagan(model.resid, model.model.exog)
                pass_het = p_het >= 0.05
                msg_het = f"Breusch-Pagan p={format_p(p_het)} (>=.05 ë§Œì¡±)" if pass_het else "ë“±ë¶„ì‚°ì„± ìœ„ë°° (p<.05)"

                if high_vif: assump_fails.append(f"ë‹¤ì¤‘ê³µì„ ì„±({', '.join(high_vif)})")
                if not pass_dw: assump_fails.append("ì”ì°¨ ë…ë¦½ì„±")
                if not pass_het: assump_fails.append("ì”ì°¨ ë“±ë¶„ì‚°ì„±")
                
                assumption_report = f"- ë‹¤ì¤‘ê³µì„ ì„±: {'ë¬¸ì œ ì—†ìŒ' if not high_vif else f'ì˜ì‹¬ ë³€ìˆ˜: {high_vif}'}<br>- ë…ë¦½ì„±: {msg_dw}<br>- ë“±ë¶„ì‚°ì„±: {msg_het}"

                conf_int = model.conf_int(alpha=0.05)
                conf_int.columns = ['Lower CI', 'Upper CI']
                
                final_df = pd.DataFrame({
                    "B (ë¹„í‘œì¤€í™” ê³„ìˆ˜)": model.params,
                    "í‘œì¤€ì˜¤ì°¨(SE)": model.bse,
                    "tê°’": model.tvalues,
                    "pê°’": model.pvalues,
                    "95% CI (Lower)": conf_int['Lower CI'],
                    "95% CI (Upper)": conf_int['Upper CI']
                }).reset_index().rename(columns={'index':'ë³€ìˆ˜ëª…'})
                
                p_val_model = model.f_pvalue
                stats_info = {'r2': model.rsquared, 'assump_fails': assump_fails}
                
            else: 
                model = sm.Logit(Y, X).fit(disp=0)
                assumption_report = "- ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ì •ê·œì„±/ë“±ë¶„ì‚°ì„± ê°€ì •ì´ ìš”êµ¬ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                
                conf_int = model.conf_int()
                odds_ratio = np.exp(model.params)
                or_ci_lower = np.exp(conf_int[0])
                or_ci_upper = np.exp(conf_int[1])
                
                final_df = pd.DataFrame({
                    "B (ê³„ìˆ˜)": model.params,
                    "í‘œì¤€ì˜¤ì°¨(SE)": model.bse,
                    "Wald Chi-Sq": np.square(model.tvalues),
                    "pê°’": model.pvalues,
                    "Odds Ratio (OR)": odds_ratio,
                    "95% CI (Lower)": or_ci_lower,
                    "95% CI (Upper)": or_ci_upper
                }).reset_index().rename(columns={'index':'ë³€ìˆ˜ëª…'})
                
                p_val_model = model.llr_pvalue
                stats_info = {'r2': model.prsquared, 'assump_fails': []}

            final_df['pê°’'] = final_df['pê°’'].apply(lambda x: f"{format_p(x)}{get_stars(x)}")
            interpretation = get_auto_interpretation("íšŒê·€ë¶„ì„", p_val_model, stats_dict=stats_info)
            plt.figure(figsize=(8, 4)); sns.heatmap(df[x_vars + [y_var]].corr(), annot=True, cmap="YlGnBu"); plot_img = get_plot_buffer()

    # ê²°ê³¼ ì¶œë ¥
    if final_df is not None:
        st.markdown('<div class="section-title"><span class="step-badge">02</span> ë¶„ì„ ê²°ê³¼ ë° ë¦¬í¬íŠ¸</div>', unsafe_allow_html=True)
        
        # ê°€ì • ê²€ì • ê²°ê³¼ë¥¼ ë°•ìŠ¤(assumption-box class) ì•ˆì— ì¶œë ¥
        if assumption_report:
            with st.expander("ğŸ” í†µê³„ì  ê°€ì • ê²€ì • ê²°ê³¼ (Assumption Checks)", expanded=True):
                st.markdown(f"""
                <div class="assumption-box">
                    {assumption_report}
                </div>
                """, unsafe_allow_html=True)
                
                if assump_fails:
                    st.error(f"âš ï¸ ìœ„ë°°ëœ ê°€ì •: {', '.join(assump_fails)} (í•´ì„ ì‹œ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.)")
                else:
                    st.success("âœ… ì£¼ìš” í†µê³„ì  ê°€ì •ì„ ëª¨ë‘ ì¶©ì¡±í•©ë‹ˆë‹¤.")

        c1, c2 = st.columns([1.5, 1])
        with c1: 
            st.table(final_df)
            st.info(interpretation)
        with c2: 
            if plot_img: st.image(plot_img)
        st.download_button("ğŸ“„ ì›Œë“œ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ", data=create_word_report(final_df, interpretation, plot_img, assumption_report), file_name=f"STATERA_Report.docx")

else:
    st.markdown("""<div class="landing-zone"><div style="font-size: 3.5rem; margin-bottom: 20px;">â¬†ï¸</div><h3 style="color: #0f172a; margin-bottom: 10px;">ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”</h3><p style="color: #64748b;">íŒŒì¼ì´ ë¡œë“œë˜ë©´ ì „ë¬¸ í†µê³„ ê°€ì´ë“œì™€ ë¶„ì„ ì˜µì…˜ì´ í™œì„±í™”ë©ë‹ˆë‹¤.</p></div>""", unsafe_allow_html=True)

# -----------------------------------------------------------------------------
# 6. ì—°êµ¬ ìœ¤ë¦¬ ì•ˆë‚´ (ìµœí•˜ë‹¨ ê³ ì •)
# -----------------------------------------------------------------------------
st.markdown(f"""
<div class="ethics-container">
    <div class="ethics-title">âš ï¸ ë¶„ì„ ê²°ê³¼ í•´ì„ ì‹œ ìœ ì˜ì‚¬í•­</div>
    <div class="ethics-text">
        1. ë³¸ ì„œë¹„ìŠ¤ì—ì„œ ì œê³µí•˜ëŠ” ìë™ í•´ì„ ë¬¸êµ¬ëŠ” ìœ ì˜ìˆ˜ì¤€ 0.05ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚°ì¶œëœ ê¸°ê³„ì  íŒì • ê²°ê³¼ì…ë‹ˆë‹¤.<br>
        2. ì—°êµ¬ìëŠ” í†µê³„ì  ìœ ì˜ì„±(p-value)ë¿ë§Œ ì•„ë‹ˆë¼, ì—°êµ¬ ëª©ì ì— ë”°ë¥¸ ì‹¤ì§ˆì /ì„ìƒì  ì˜ë¯¸ë¥¼ ë°˜ë“œì‹œ í•¨ê»˜ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.<br>
        3. ìµœì¢… ë³´ê³ ì„œ ì‘ì„± ì‹œ ë³¸ í•´ì„ì˜ ì •í™•ì„±ì„ ê²€í† í•  ì±…ì„ì€ ì—°êµ¬ì ë³¸ì¸ì—ê²Œ ìˆìŠµë‹ˆë‹¤.<br>
        4. ë°ì´í„°ì˜ ì •ê·œì„±, ë“±ë¶„ì‚°ì„± ë“± í†µê³„ì  ê¸°ë³¸ ê°€ì •ì´ ì¶©ì¡±ë˜ì—ˆëŠ”ì§€ ì‚¬ì „ì— í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
    </div>
</div>
""", unsafe_allow_html=True)

st.markdown("<div style='text-align: center; color: #cbd5e1; margin-top: 20px; font-size: 0.8rem;'>STATistical Engine for Research & Analysis | ANDA Lab Jeongin Choe</div>", unsafe_allow_html=True)
